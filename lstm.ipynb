{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ewcksZIRLbL6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A05aNPMLedz",
        "outputId": "6adb7840-0773-4c25-ad86-7b89b778b22e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd /content/drive/MyDrive/Georgetown/BrainDecoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxmwCQTTLg2R",
        "outputId": "cfb08524-083d-4e1e-c1d5-1894bc9f70f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Georgetown/BrainDecoding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "taGzxajaLbL6"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
        "        self.activation = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)\n",
        "        # Initialize cell state with zeros\n",
        "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))  # shape (batch_size, seq_length, hidden_size)\n",
        "        out = self.fc(out[:, -1, :])  # shape (batch_size, output_size)\n",
        "        out = self.activation(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Xku2h5y2NHCl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eLnudphPLbL7"
      },
      "outputs": [],
      "source": [
        "input_size = 200  # Dimensionality of each image vector\n",
        "hidden_size = 128\n",
        "num_layers = 8\n",
        "output_size = 1\n",
        "lr = 0.001\n",
        "num_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pwe7nXMzLbL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e5a074-4547-4f9f-931c-539330060a3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3105025\n"
          ]
        }
      ],
      "source": [
        "model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(pytorch_total_params)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nDAJGqO9LbL7"
      },
      "outputs": [],
      "source": [
        "Xtrain = torch.load('preprocessed_data/Xtrain.pt').to(device)\n",
        "ytrain = torch.load('preprocessed_data/ytrain.pt').unsqueeze(1).to(device)\n",
        "Xdev = torch.load('preprocessed_data/Xdev.pt').to(device)\n",
        "ydev= torch.load('preprocessed_data/ydev.pt').unsqueeze(1).to(device)\n",
        "Xtest = torch.load('preprocessed_data/Xtest.pt').to(device)\n",
        "ytest= torch.load('preprocessed_data/ytest.pt').unsqueeze(1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA_IYT2WLbL7",
        "outputId": "cf1741fe-f8aa-4cd3-b865-47ab2a4704e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.6931\n",
            "0.48605119355766463\n",
            "Epoch [2/100], Loss: 0.6933\n",
            "0.48605119355766463\n",
            "Epoch [3/100], Loss: 0.6931\n",
            "0.5139488064423353\n",
            "Epoch [4/100], Loss: 0.6930\n",
            "0.5139488064423353\n",
            "Epoch [5/100], Loss: 0.6931\n",
            "0.5139488064423353\n",
            "Epoch [6/100], Loss: 0.6933\n",
            "0.5139488064423353\n",
            "Epoch [7/100], Loss: 0.6930\n",
            "0.5139488064423353\n",
            "Epoch [8/100], Loss: 0.6921\n",
            "0.5139488064423353\n",
            "Epoch [9/100], Loss: 0.6902\n",
            "0.5148116192119644\n",
            "Epoch [10/100], Loss: 0.6871\n",
            "0.5257405809605982\n",
            "Epoch [11/100], Loss: 0.6826\n",
            "0.5349439171699741\n",
            "Epoch [12/100], Loss: 0.6785\n",
            "0.5329306873741732\n",
            "Epoch [13/100], Loss: 0.6793\n",
            "0.541558815070463\n",
            "Epoch [14/100], Loss: 0.6805\n",
            "0.5524877768190969\n",
            "Epoch [15/100], Loss: 0.6776\n",
            "0.5536381938452689\n",
            "Epoch [16/100], Loss: 0.6811\n",
            "0.5579522576934138\n",
            "Epoch [17/100], Loss: 0.6869\n",
            "0.5616911130284729\n",
            "Epoch [18/100], Loss: 0.6847\n",
            "0.5634167385677308\n",
            "Epoch [19/100], Loss: 0.6788\n",
            "0.5634167385677308\n",
            "Epoch [20/100], Loss: 0.6778\n",
            "0.5631291343111878\n",
            "Epoch [21/100], Loss: 0.6823\n",
            "0.48605119355766463\n",
            "Epoch [22/100], Loss: 0.6876\n",
            "0.48605119355766463\n",
            "Epoch [23/100], Loss: 0.6908\n",
            "0.48605119355766463\n",
            "Epoch [24/100], Loss: 0.6921\n",
            "0.48605119355766463\n",
            "Epoch [25/100], Loss: 0.6922\n",
            "0.48605119355766463\n",
            "Epoch [26/100], Loss: 0.6920\n",
            "0.544722461892436\n",
            "Epoch [27/100], Loss: 0.6918\n",
            "0.5234397469082542\n",
            "Epoch [28/100], Loss: 0.6918\n",
            "0.5156744319815934\n",
            "Epoch [29/100], Loss: 0.6920\n",
            "0.5145240149554213\n",
            "Epoch [30/100], Loss: 0.6924\n",
            "0.5150992234685073\n",
            "Epoch [31/100], Loss: 0.6930\n",
            "0.5136612021857924\n",
            "Epoch [32/100], Loss: 0.6936\n",
            "0.5139488064423353\n",
            "Epoch [33/100], Loss: 0.6944\n",
            "0.5136612021857924\n",
            "Epoch [34/100], Loss: 0.6951\n",
            "0.5139488064423353\n",
            "Epoch [35/100], Loss: 0.6956\n",
            "0.5139488064423353\n",
            "Epoch [36/100], Loss: 0.6958\n",
            "0.5139488064423353\n",
            "Epoch [37/100], Loss: 0.6955\n",
            "0.5139488064423353\n",
            "Epoch [38/100], Loss: 0.6947\n",
            "0.5139488064423353\n",
            "Epoch [39/100], Loss: 0.6939\n",
            "0.5139488064423353\n",
            "Epoch [40/100], Loss: 0.6933\n",
            "0.4834627552487777\n",
            "Epoch [41/100], Loss: 0.6934\n",
            "0.48605119355766463\n",
            "Epoch [42/100], Loss: 0.6942\n",
            "0.48633879781420764\n",
            "Epoch [43/100], Loss: 0.6951\n",
            "0.48605119355766463\n",
            "Epoch [44/100], Loss: 0.6956\n",
            "0.48605119355766463\n",
            "Epoch [45/100], Loss: 0.6954\n",
            "0.48605119355766463\n",
            "Epoch [46/100], Loss: 0.6946\n",
            "0.48605119355766463\n",
            "Epoch [47/100], Loss: 0.6938\n",
            "0.48605119355766463\n",
            "Epoch [48/100], Loss: 0.6931\n",
            "0.5139488064423353\n",
            "Epoch [49/100], Loss: 0.6931\n",
            "0.5139488064423353\n",
            "Epoch [50/100], Loss: 0.6939\n",
            "0.5139488064423353\n",
            "Epoch [51/100], Loss: 0.6954\n",
            "0.5139488064423353\n",
            "Epoch [52/100], Loss: 0.6974\n",
            "0.5139488064423353\n",
            "Epoch [53/100], Loss: 0.6996\n",
            "0.5139488064423353\n",
            "Epoch [54/100], Loss: 0.7014\n",
            "0.5139488064423353\n",
            "Epoch [55/100], Loss: 0.7024\n",
            "0.5139488064423353\n",
            "Epoch [56/100], Loss: 0.7026\n",
            "0.5139488064423353\n",
            "Epoch [57/100], Loss: 0.7021\n",
            "0.5139488064423353\n",
            "Epoch [58/100], Loss: 0.7009\n",
            "0.5133735979292493\n",
            "Epoch [59/100], Loss: 0.6993\n",
            "0.5142364106988784\n",
            "Epoch [60/100], Loss: 0.6976\n",
            "0.5153868277250503\n",
            "Epoch [61/100], Loss: 0.6960\n",
            "0.5136612021857924\n",
            "Epoch [62/100], Loss: 0.6944\n",
            "0.5142364106988784\n",
            "Epoch [63/100], Loss: 0.6932\n",
            "0.5122231809030774\n",
            "Epoch [64/100], Loss: 0.6926\n",
            "0.4854759850445787\n",
            "Epoch [65/100], Loss: 0.6933\n",
            "0.48518838078803567\n",
            "Epoch [66/100], Loss: 0.6964\n",
            "0.4857635893011217\n",
            "Epoch [67/100], Loss: 0.7002\n",
            "0.48605119355766463\n",
            "Epoch [68/100], Loss: 0.7007\n",
            "0.48605119355766463\n",
            "Epoch [69/100], Loss: 0.6986\n",
            "0.4854759850445787\n",
            "Epoch [70/100], Loss: 0.6958\n",
            "0.4840379637618637\n",
            "Epoch [71/100], Loss: 0.6939\n",
            "0.48461317227494966\n",
            "Epoch [72/100], Loss: 0.6931\n",
            "0.48432556801840665\n",
            "Epoch [73/100], Loss: 0.6932\n",
            "0.48461317227494966\n",
            "Epoch [74/100], Loss: 0.6933\n",
            "0.48490077653149266\n",
            "Epoch [75/100], Loss: 0.6937\n",
            "0.48605119355766463\n",
            "Epoch [76/100], Loss: 0.6938\n",
            "0.48633879781420764\n",
            "Epoch [77/100], Loss: 0.6940\n",
            "0.48605119355766463\n",
            "Epoch [78/100], Loss: 0.6942\n",
            "0.48605119355766463\n",
            "Epoch [79/100], Loss: 0.6942\n",
            "0.48605119355766463\n",
            "Epoch [80/100], Loss: 0.6943\n",
            "0.48605119355766463\n",
            "Epoch [81/100], Loss: 0.6943\n",
            "0.48605119355766463\n",
            "Epoch [82/100], Loss: 0.6942\n",
            "0.48662640207075064\n",
            "Epoch [83/100], Loss: 0.6942\n",
            "0.48633879781420764\n",
            "Epoch [84/100], Loss: 0.6941\n",
            "0.48633879781420764\n",
            "Epoch [85/100], Loss: 0.6940\n",
            "0.48691400632729365\n",
            "Epoch [86/100], Loss: 0.6938\n",
            "0.48518838078803567\n",
            "Epoch [87/100], Loss: 0.6937\n",
            "0.48633879781420764\n",
            "Epoch [88/100], Loss: 0.6936\n",
            "0.4854759850445787\n",
            "Epoch [89/100], Loss: 0.6934\n",
            "0.48605119355766463\n",
            "Epoch [90/100], Loss: 0.6933\n",
            "0.48605119355766463\n",
            "Epoch [91/100], Loss: 0.6932\n",
            "0.5142364106988784\n",
            "Epoch [92/100], Loss: 0.6931\n",
            "0.5136612021857924\n",
            "Epoch [93/100], Loss: 0.6931\n",
            "0.5142364106988784\n",
            "Epoch [94/100], Loss: 0.6931\n",
            "0.5145240149554213\n",
            "Epoch [95/100], Loss: 0.6931\n",
            "0.5145240149554213\n",
            "Epoch [96/100], Loss: 0.6932\n",
            "0.5148116192119644\n",
            "Epoch [97/100], Loss: 0.6933\n",
            "0.5148116192119644\n",
            "Epoch [98/100], Loss: 0.6935\n",
            "0.5150992234685073\n",
            "Epoch [99/100], Loss: 0.6938\n",
            "0.5148116192119644\n",
            "Epoch [100/100], Loss: 0.6940\n",
            "0.5139488064423353\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    outputs = model(Xtrain)\n",
        "    loss = criterion(outputs, ytrain)\n",
        "    #optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        op = model(Xdev).squeeze()\n",
        "        op_cpu = op.cpu()\n",
        "        ydev_cpu = ydev.cpu()\n",
        "        preds = [int(o.item()>0.5) for o in op_cpu]\n",
        "        print(accuracy_score(ydev_cpu,preds))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "      model.eval()\n",
        "      op = model(Xdev).squeeze()\n",
        "      op_cpu = op.cpu()\n",
        "      ydev_cpu = ydev.cpu()\n",
        "      preds = [int(o.item()>0.5) for o in op_cpu]\n",
        "      print(accuracy_score(ydev_cpu,preds))\n",
        "      print(classification_report(ydev_cpu,preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ib0Vf4Hj3pE",
        "outputId": "7421962e-5245-4de0-b3c9-7f655f41833e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.542134023583549\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.54      0.42      0.47      1690\n",
            "         1.0       0.55      0.66      0.60      1787\n",
            "\n",
            "    accuracy                           0.54      3477\n",
            "   macro avg       0.54      0.54      0.53      3477\n",
            "weighted avg       0.54      0.54      0.54      3477\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "      model.eval()\n",
        "      op = model(Xtest).squeeze()\n",
        "      op_cpu = op.cpu()\n",
        "      ytest_cpu = ytest.cpu()\n",
        "      preds = [int(o.item()>0.5) for o in op_cpu]\n",
        "      print(accuracy_score(ytest_cpu,preds))\n",
        "      print(classification_report(ytest_cpu,preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpN-4vqtkHT2",
        "outputId": "92d34328-1e82-491f-aaa8-d20f96b374b5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5602154674874952\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      0.52      0.56      2816\n",
            "         1.0       0.52      0.61      0.56      2382\n",
            "\n",
            "    accuracy                           0.56      5198\n",
            "   macro avg       0.56      0.56      0.56      5198\n",
            "weighted avg       0.57      0.56      0.56      5198\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}